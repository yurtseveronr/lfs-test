name: S3 CFN Deploy & All Files Upload
on:
  workflow_dispatch:
permissions:
  id-token: write
  contents: read
jobs:
  deploy-and-upload-all:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository with LFS
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: true
          
      - name: Configure Git LFS and checkout files
        run: |
          git lfs install
          git lfs pull
          
      - name: Verify LFS files are downloaded
        run: |
          echo "Checking LFS files status:"
          git lfs ls-files -l
          echo ""
          echo "CSV file sizes:"
          find . -name "*.csv" -exec ls -lh {} \;
          
      - name: Configure AWS Credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::708778582346:role/onur-github-role
          aws-region: us-east-1
          
      - name: Deploy S3 CloudFormation Stack
        run: |
          aws cloudformation deploy \
            --template-file cloudformation_templates/s3.yml \
            --stack-name s3-bucket-stack \
            --region us-east-1 \
            --capabilities CAPABILITY_NAMED_IAM
            
      - name: Retrieve Bucket Name
        id: get-bucket
        run: |
          # Try to get bucket name from CloudFormation
          BUCKET_NAME=$(aws cloudformation describe-stacks \
            --stack-name s3-bucket-stack \
            --region us-east-1 \
            --query "Stacks[0].Outputs[?OutputKey=='BucketName'].OutputValue" \
            --output text 2>/dev/null || echo "None")
          
          # If CloudFormation fails or returns None, use fallback
          if [ "$BUCKET_NAME" = "None" ] || [ -z "$BUCKET_NAME" ]; then
            echo "CloudFormation bucket name not found, using fallback: onur-master-dataset"
            BUCKET_NAME="onur-master-dataset"
          fi
          
          echo "Using bucket: $BUCKET_NAME"
          echo "bucket=$BUCKET_NAME" >> $GITHUB_OUTPUT
            
      - name: Upload all files to S3
        run: |
          BUCKET=${{ steps.get-bucket.outputs.bucket }}
          echo "Using bucket: $BUCKET"
          
          echo "Uploading all files to s3://$BUCKET/"
          
          # Find and upload all files (excluding git and system folders)
          find . -type f \
            ! -path "./.git/*" \
            ! -path "./.github/*" \
            ! -path "*/node_modules/*" \
            ! -path "*/\.DS_Store" \
            ! -path "*/__pycache__/*" \
            ! -path "*/\.vscode/*" \
            ! -path "*/\.idea/*" \
          | sed 's|^\./||' \
          | while read file; do
              if [ -f "$file" ]; then
                file_size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo "unknown")
                file_ext="${file##*.}"
                
                echo "‚Üí Uploading: $file (size: $file_size bytes, type: $file_ext)"
                
                # Special handling for CSV files (LFS support)
                if [[ "$file_ext" == "csv" ]] || [[ "$file_ext" == "CSV" ]]; then
                  echo "  üìä CSV file detected - using LFS optimized upload"
                  # Use multipart upload for CSV files (they're likely large due to LFS)
                  aws s3 cp "$file" "s3://$BUCKET/$file" --storage-class STANDARD
                # Use multipart upload for other large files
                elif [ "$file_size" != "unknown" ] && [ "$file_size" -gt 104857600 ]; then
                  echo "  üì¶ Large file detected - using multipart upload"
                  aws s3 cp "$file" "s3://$BUCKET/$file" --storage-class STANDARD
                else
                  # Standard upload for smaller files
                  aws s3 cp "$file" "s3://$BUCKET/$file"
                fi
              else
                echo "‚ö†Ô∏è  File not found: $file"
              fi
            done
            
      - name: Verify upload success
        run: |
          BUCKET=${{ steps.get-bucket.outputs.bucket }}
          echo "Verifying uploaded files:"
          echo ""
          echo "üìä CSV files:"
          aws s3 ls "s3://$BUCKET/" --recursive --human-readable | grep -i "\.csv" || echo "No CSV files found"
          echo ""
          echo "üìÅ All files:"
          aws s3 ls "s3://$BUCKET/" --recursive --human-readable | head -20
          echo ""
          echo "üìà Total file count:"
          aws s3 ls "s3://$BUCKET/" --recursive | wc -l
